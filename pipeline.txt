The current pipeline, this file is just different commands someone can execute
Note that the folder with data and folder with pickled data is located outside
the git repository

In my local enviorenment the folders are located as follows:
../thesis/data/ -> folder with corpus (subsets)
../thesis/pickle/ -> folder with pickled X_trans, y_trans, model

execute commands in the framework folder
python3 extract_open_corpus.py #given open corpus file, extract data to TREC format (not usuable atm)
python3 loader.py #fill config file
python3 data_combining.py #print data of specific article

Step 1, create subset for corpus:
python3 create_corpus_subset.py -t ../data2019/fair-TREC-training-sample.json -o ../data2019/corpus-subset-for-queries.jsonl

Step 2, extract corpus:
python3 extract_open_corpus.py -c ../data2019/corpus-subset-for-queries.jsonl -s ../data2019/

Step 3, update config file

Step 4, extract features and store it in libsvm format:
python3 feature_extraction.py -f ../data2019/fair-TREC-training-sample.json -o ../features/libsvm.txt

Step 5, train using
python3 training.py -f ../features/libsvm.txt -p ../pickle/

Step 6, score model
python3 training.py --score -p ../pickle/
python3 model_ranking.py -m ../model2019/model -f ../features2019/libsvm.txt
